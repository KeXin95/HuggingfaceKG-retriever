{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7aceb7d-3759-4606-88b7-1dd7bc54bb19",
   "metadata": {},
   "source": [
    "# PyTorch GCN Implementation\n",
    "\n",
    "This section implements a Graph Convolutional Network (GCN) from scratch using PyTorch, replicating the functionality from your CogDL setup.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "2377ce1e-8d19-4c6b-9fb7-e415dcc9af3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear\n",
    "import torch.optim as optim\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.data import Data\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "2f1f2d1a-4cb7-4068-bf48-1a5bf4becaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(nn.Module):\n",
    "    def __init__(self, num_features, hidden_size, num_classes, num_layers=2, dropout=0.5):\n",
    "        super(GCN, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        # Input layer\n",
    "        self.convs = nn.ModuleList()\n",
    "        self.convs.append(GCNConv(num_features, hidden_size))\n",
    "        \n",
    "        # Hidden layers\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.convs.append(GCNConv(hidden_size, hidden_size))\n",
    "        \n",
    "        # Output layer\n",
    "        if num_layers > 1:\n",
    "            self.convs.append(GCNConv(hidden_size, num_classes))\n",
    "        else:\n",
    "            self.convs.append(GCNConv(num_features, num_classes))\n",
    "    \n",
    "    def forward(self, x, edge_index):\n",
    "        for i, conv in enumerate(self.convs):\n",
    "            x = conv(x, edge_index)\n",
    "            if i < len(self.convs) - 1:  # Don't apply activation to last layer\n",
    "                x = F.relu(x)\n",
    "                x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44bc1a5-e570-49e7-b6fe-ae4e1c6c4ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "e71c7c27-37a2-465c-8247-d0ecfd8ed646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original edge_index type: <class 'tuple'>\n",
      "Edge_index is a tuple with 2 elements\n",
      "First element type: <class 'torch.Tensor'>, shape: torch.Size([124056])\n",
      "Second element type: <class 'torch.Tensor'>, shape: torch.Size([124056])\n",
      "Converted edge_index shape: torch.Size([2, 124056])\n",
      "Converted edge_index dtype: torch.int64\n"
     ]
    }
   ],
   "source": [
    "# Initialize model\n",
    "# Training configuration (matching your CogDL setup)\n",
    "graph = torch.load('./experiment_runs/run_2025-09-26_22-12-13/final_graph.pt')\n",
    "pyg_data = convert_graph_to_pyg(graph)\n",
    "\n",
    "config = {\n",
    "    'num_layers': 2,\n",
    "    'lr': 0.001,\n",
    "    'hidden_size': 64,\n",
    "    'epochs': 500,\n",
    "    'weight_decay': 0,\n",
    "    'patience': 100,\n",
    "    'dropout': 0.5\n",
    "}\n",
    "# Extract data dimensions\n",
    "num_features = pyg_data.x.shape[1]\n",
    "num_classes = pyg_data.y.shape[1]\n",
    "\n",
    "model = GCN(\n",
    "    num_features=num_features,\n",
    "    hidden_size=config['hidden_size'],\n",
    "    num_classes=num_classes,\n",
    "    num_layers=config['num_layers'],\n",
    "    dropout=config.get('dropout', 0.5)\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "bfe3ac64-7e42-46b7-9288-486c678295a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GCN(\n",
       "  (convs): ModuleList(\n",
       "    (0): GCNConv(768, 64)\n",
       "    (1): GCNConv(64, 54)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5a345b-738d-4a52-85ce-14f6b6199d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "708c6a0b-e083-4746-9e9c-cd5787455b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, data, optimizer, criterion, device):\n",
    "    \"\"\"Train the model for one epoch\"\"\"\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Forward pass\n",
    "    logits = model(data.x, data.edge_index)\n",
    "    \n",
    "    # Get predictions for training nodes only\n",
    "    train_logits = logits[data.train_mask]\n",
    "    train_labels = data.y[data.train_mask]\n",
    "    \n",
    "    # Compute loss\n",
    "    loss = criterion(train_logits, train_labels.float())\n",
    "    \n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss.item()\n",
    "\n",
    "def evaluate_model(model, data, criterion, device, mask_name='val'):\n",
    "    \"\"\"Evaluate the model on validation or test set\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        logits = model(data.x, data.edge_index)\n",
    "        \n",
    "        if mask_name == 'val':\n",
    "            mask = data.val_mask\n",
    "        elif mask_name == 'test':\n",
    "            mask = data.test_mask\n",
    "        else:\n",
    "            mask = data.train_mask\n",
    "            \n",
    "        eval_logits = logits[mask]\n",
    "        eval_labels = data.y[mask]\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = criterion(eval_logits, eval_labels.float())\n",
    "        \n",
    "        # Apply sigmoid to convert logits to probabilities\n",
    "        probs = torch.sigmoid(eval_logits)\n",
    "        \n",
    "        # Convert probabilities to binary predictions (threshold at 0.5)\n",
    "        predictions = (probs > 0.5).float()\n",
    "        \n",
    "        # Compute accuracy as fraction of correctly predicted labels\n",
    "        accuracy = (predictions == eval_labels).float().mean().item()\n",
    "        \n",
    "        # Compute F1 score (micro-averaged)\n",
    "        f1 = f1_score(eval_labels.cpu().numpy(), predictions.cpu().numpy(), average='micro')\n",
    "        \n",
    "    return loss.item(), accuracy, f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "dd2cd7e4-09be-4666-99ef-2a22f041cb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gcn(data, config, device='cpu'):\n",
    "    \"\"\"Main training function\"\"\"\n",
    "    \n",
    "    # Extract data dimensions\n",
    "    num_features = data.x.shape[1]\n",
    "    num_classes = data.y.shape[1]\n",
    "    \n",
    "    # Initialize model\n",
    "    model = GCN(\n",
    "        num_features=num_features,\n",
    "        hidden_size=config['hidden_size'],\n",
    "        num_classes=num_classes,\n",
    "        num_layers=config['num_layers'],\n",
    "        dropout=config.get('dropout', 0.5)\n",
    "    ).to(device)\n",
    "    print(model)\n",
    "    \n",
    "    # Move data to device\n",
    "    data = data.to(device)\n",
    "    \n",
    "    # Initialize optimizer and loss function\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=config['lr'], weight_decay=config.get('weight_decay', 0))\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    # Training history\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    val_accuracies = []\n",
    "    val_f1_scores = []\n",
    "    \n",
    "    best_val_f1 = 0\n",
    "    patience_counter = 0\n",
    "    best_model_state = None\n",
    "    \n",
    "    print(f\"Starting training with config: {config}\")\n",
    "    print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in tqdm(range(config['epochs']), desc=\"Training\"):\n",
    "        # Train\n",
    "        train_loss = train_model(model, data, optimizer, criterion, device)\n",
    "        \n",
    "        # Validate\n",
    "        val_loss, val_acc, val_f1 = evaluate_model(model, data, criterion, device, 'val')\n",
    "        \n",
    "        # Store metrics\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        val_accuracies.append(val_acc)\n",
    "        val_f1_scores.append(val_f1)\n",
    "        \n",
    "        # Early stopping\n",
    "        if val_f1 > best_val_f1:\n",
    "            best_val_f1 = val_f1\n",
    "            patience_counter = 0\n",
    "            best_model_state = model.state_dict().copy()\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            \n",
    "        if patience_counter >= config.get('patience', 100):\n",
    "            print(f\"Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "            \n",
    "        # Print progress\n",
    "        if (epoch + 1) % 50 == 0:\n",
    "            print(f\"Epoch {epoch+1}: Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, \"\n",
    "                  f\"Val Acc: {val_acc:.4f}, Val F1: {val_f1:.4f}\")\n",
    "    \n",
    "    # Load best model\n",
    "    if best_model_state is not None:\n",
    "        model.load_state_dict(best_model_state)\n",
    "    \n",
    "    # Final evaluation\n",
    "    test_loss, test_acc, test_f1 = evaluate_model(model, data, criterion, device, 'test')\n",
    "    \n",
    "    print(f\"\\nFinal Results:\")\n",
    "    print(f\"Best Val F1: {best_val_f1:.4f}\")\n",
    "    print(f\"Test Loss: {test_loss:.4f}\")\n",
    "    print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "    print(f\"Test F1: {test_f1:.4f}\")\n",
    "    \n",
    "    return {\n",
    "        'model': model,\n",
    "        'train_losses': train_losses,\n",
    "        'val_losses': val_losses,\n",
    "        'val_accuracies': val_accuracies,\n",
    "        'val_f1_scores': val_f1_scores,\n",
    "        'best_val_f1': best_val_f1,\n",
    "        'test_loss': test_loss,\n",
    "        'test_accuracy': test_acc,\n",
    "        'test_f1': test_f1\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5be7dba6-b02b-4285-aa65-f7523e87b160",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def convert_graph_to_pyg(graph):\n",
    "    \"\"\"Convert CogDL graph to PyTorch Geometric Data format\"\"\"\n",
    "    \n",
    "    # Extract features and labels\n",
    "    x = graph.x  # Node features\n",
    "    y = graph.y  # Node labels (multi-label)\n",
    "    \n",
    "    # Extract edge information and ensure it's in the correct format\n",
    "    edge_index = graph.edge_index\n",
    "    \n",
    "    # Debug: Check edge_index format\n",
    "    print(f\"Original edge_index type: {type(edge_index)}\")\n",
    "    \n",
    "    # Handle different edge_index formats\n",
    "    if isinstance(edge_index, tuple):\n",
    "        # If it's a tuple, it's likely (source_nodes, target_nodes)\n",
    "        print(f\"Edge_index is a tuple with {len(edge_index)} elements\")\n",
    "        print(f\"First element type: {type(edge_index[0])}, shape: {edge_index[0].shape if hasattr(edge_index[0], 'shape') else 'no shape'}\")\n",
    "        print(f\"Second element type: {type(edge_index[1])}, shape: {edge_index[1].shape if hasattr(edge_index[1], 'shape') else 'no shape'}\")\n",
    "        \n",
    "        # Convert tuple to tensor format [2, num_edges]\n",
    "        source_nodes = edge_index[0]\n",
    "        target_nodes = edge_index[1]\n",
    "        \n",
    "        # Stack them to create [2, num_edges] format\n",
    "        edge_index = torch.stack([source_nodes, target_nodes], dim=0).long()\n",
    "        \n",
    "    elif hasattr(edge_index, 'shape'):\n",
    "        print(f\"Original edge_index shape: {edge_index.shape}\")\n",
    "        print(f\"Original edge_index dtype: {edge_index.dtype}\")\n",
    "        \n",
    "        # Convert to proper format if needed\n",
    "        if hasattr(edge_index, 'to_dense'):\n",
    "            # If it's a sparse tensor, convert to dense then to edge_index format\n",
    "            dense_adj = edge_index.to_dense()\n",
    "            edge_index = torch.nonzero(dense_adj, as_tuple=False).t().contiguous()\n",
    "        elif edge_index.dim() == 2 and edge_index.shape[0] != 2:\n",
    "            # If it's [num_edges, 2], transpose to [2, num_edges]\n",
    "            edge_index = edge_index.t().contiguous()\n",
    "        elif edge_index.dim() == 3:\n",
    "            # If it's a batch format, take the first (and only) graph\n",
    "            edge_index = edge_index[0]\n",
    "        \n",
    "        # Ensure it's a long tensor (integer type)\n",
    "        edge_index = edge_index.long()\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected edge_index type: {type(edge_index)}\")\n",
    "    \n",
    "    # Extract masks\n",
    "    train_mask = graph.train_mask\n",
    "    val_mask = graph.val_mask\n",
    "    test_mask = graph.test_mask\n",
    "    \n",
    "    print(f\"Converted edge_index shape: {edge_index.shape}\")\n",
    "    print(f\"Converted edge_index dtype: {edge_index.dtype}\")\n",
    "    \n",
    "    # Create PyTorch Geometric Data object\n",
    "    data = Data(\n",
    "        x=x,\n",
    "        edge_index=edge_index,\n",
    "        y=y,\n",
    "        train_mask=train_mask,\n",
    "        val_mask=val_mask,\n",
    "        test_mask=test_mask\n",
    "    )\n",
    "    \n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "20b09b8f-3f16-4dab-9098-f1a5eb0fbc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = torch.load('./experiment_runs/run_2025-09-26_22-12-13/final_graph.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "ea7f8e0d-d129-4772-9206-879b942bcec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original edge_index type: <class 'tuple'>\n",
      "Edge_index is a tuple with 2 elements\n",
      "First element type: <class 'torch.Tensor'>, shape: torch.Size([124056])\n",
      "Second element type: <class 'torch.Tensor'>, shape: torch.Size([124056])\n",
      "Converted edge_index shape: torch.Size([2, 124056])\n",
      "Converted edge_index dtype: torch.int64\n",
      "PyTorch Geometric Data:\n",
      "  Nodes: 389066\n",
      "  Features: 768\n",
      "  Classes: 54\n",
      "  Edges: 124056\n",
      "  Train nodes: 327765\n",
      "  Val nodes: 19444\n",
      "  Test nodes: 6078\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pyg_data = convert_graph_to_pyg(graph)\n",
    "print(f\"PyTorch Geometric Data:\")\n",
    "print(f\"  Nodes: {pyg_data.num_nodes}\")\n",
    "print(f\"  Features: {pyg_data.num_features}\")\n",
    "print(f\"  Classes: {pyg_data.y.shape[1]}\")\n",
    "print(f\"  Edges: {pyg_data.num_edges}\")\n",
    "print(f\"  Train nodes: {pyg_data.train_mask.sum()}\")\n",
    "print(f\"  Val nodes: {pyg_data.val_mask.sum()}\")\n",
    "print(f\"  Test nodes: {pyg_data.test_mask.sum()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "81990930-8c14-4eb2-9148-c0fe3b2f02a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "GCN(\n",
      "  (convs): ModuleList(\n",
      "    (0): GCNConv(768, 256)\n",
      "    (1): GCNConv(256, 54)\n",
      "  )\n",
      ")\n",
      "Starting training with config: {'num_layers': 2, 'lr': 0.001, 'hidden_size': 256, 'epochs': 500, 'weight_decay': 0, 'patience': 100, 'dropout': 0.5}\n",
      "Model parameters: 210,742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 51/500 [00:09<01:20,  5.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50: Train Loss: 0.0728, Val Loss: 0.0739, Val Acc: 0.9794, Val F1: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|██        | 101/500 [00:18<01:11,  5.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100: Train Loss: 0.0636, Val Loss: 0.0674, Val Acc: 0.9794, Val F1: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  21%|██        | 105/500 [00:19<01:11,  5.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 106\n",
      "\n",
      "Final Results:\n",
      "Best Val F1: 0.0473\n",
      "Test Loss: 0.1077\n",
      "Test Accuracy: 0.9753\n",
      "Test F1: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# Training configuration (matching your CogDL setup)\n",
    "config = {\n",
    "    'num_layers': 2,\n",
    "    'lr': 0.001,\n",
    "    'hidden_size': 256,\n",
    "    'epochs': 500,\n",
    "    'weight_decay': 0,\n",
    "    'patience': 100,\n",
    "    'dropout': 0.5\n",
    "}\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Train the model\n",
    "results = train_gcn(pyg_data, config, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd987cf-1a1c-4bb2-be36-9aa71cd95ec7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example predictions\n",
    "logits = results['model'](pyg_data.x, pyg_data.edge_index)\n",
    "labels = pyg_data.y\n",
    "\n",
    "probs = torch.sigmoid(logits)\n",
    "\n",
    "predictions = (probs > 0.5).float()\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d971d9bf-855c-41fc-b4ca-fd83f7c6aaf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as 'trained_gcn_pytorch.pt'\n",
      "Training results saved as 'training_results.pkl'\n"
     ]
    }
   ],
   "source": [
    "# Save the trained model\n",
    "torch.save(results['model'].state_dict(), 'trained_gcn_pytorch.pt')\n",
    "print(\"Model saved as 'trained_gcn_pytorch.pt'\")\n",
    "\n",
    "# You can also save the entire results dictionary for later analysis\n",
    "import pickle\n",
    "with open('training_results.pkl', 'wb') as f:\n",
    "    pickle.dump(results, f)\n",
    "print(\"Training results saved as 'training_results.pkl'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
